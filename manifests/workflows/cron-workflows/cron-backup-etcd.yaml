apiVersion: argoproj.io/v1alpha1
kind: CronWorkflow
metadata:
  name: cron-backup-etcd
  namespace: workflows
spec:
  schedule: "15 * * * *"  # Every hour at 15 minutes past the hour
  timezone: "UTC"
  concurrencyPolicy: "Replace"
  startingDeadlineSeconds: 300
  successfulJobsHistoryLimit: 3
  failedJobsHistoryLimit: 1
  workflowSpec:
    entrypoint: backup-etcd
    serviceAccountName: argo-workflow
    templates:
      - name: backup-etcd
        steps:
          - - name: backup
              template: backup

      - name: backup
        container:
          image: ghcr.io/micxba/tools:latest
          command: ["/bin/sh", "-c"]
          args:
            - |
              #!/usr/bin/env bash
              set -euo pipefail

              export TALOSCONFIG=/tmp/talos/config

              DATE=$(date +%Y%m%d%H%M)
              SNAPSHOT="ruleof3-k8s-etcd-${DATE}.snapshot"
              BACKUP_FILES=()

              # List your control-plane and worker node IPs/hostnames here
              CONTROL_PLANES=(192.168.0.216 192.168.0.228 192.168.0.236)
              WORKER_NODES=(192.168.0.220 192.168.0.156 192.168.0.224)

              # Take etcd snapshot from the first control-plane node
              FIRST_CP="${CONTROL_PLANES[0]}"
              talosctl -n "$FIRST_CP" etcd snapshot "$SNAPSHOT"
              BACKUP_FILES+=("$SNAPSHOT")

              # Backup control-plane configs
              for cp_ip in "${CONTROL_PLANES[@]}"; do
                last_octet="${cp_ip##*.}"
                cp_file="cp${last_octet}.yaml"
                talosctl -n "$cp_ip" get mc v1alpha1 -o yaml | yq -o=yaml '.spec' > "$cp_file"
                BACKUP_FILES+=("$cp_file")
              done

              # Backup worker node configs
              for wn_ip in "${WORKER_NODES[@]}"; do
                last_octet="${wn_ip##*.}"
                wn_file="wn${last_octet}.yaml"
                talosctl -n "$wn_ip" get mc v1alpha1 -o yaml | yq -o=yaml '.spec' > "$wn_file"
                BACKUP_FILES+=("$wn_file")
              done

              # Create tarball
              TARBALL="cluster-backup-${DATE}.tar.gz"
              tar -zcf "$TARBALL" "${BACKUP_FILES[@]}"

              # Upload to S3
              aws s3 cp "$TARBALL" s3://etcd-backups/ \
                --endpoint-url http://s3.sith.network:3900 \
                --no-progress


          env:
            - name: AWS_ACCESS_KEY_ID
              valueFrom:
                secretKeyRef:
                  name: argo-w-minios3
                  key: access_key
            - name: AWS_SECRET_ACCESS_KEY
              valueFrom:
                secretKeyRef:
                  name: argo-w-minios3
                  key: secret_key
          volumeMounts:
            - name: talosconfig
              mountPath: /tmp/talos
              readOnly: true

    volumes:
      - name: talosconfig
        secret:
          secretName: talosconfig
